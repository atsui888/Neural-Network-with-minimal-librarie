{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62fb42a-c22e-4dab-9d5f-a300e12ab1f7",
   "metadata": {},
   "source": [
    "# Create a NN library which uses as few libs as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4f413-7baa-45cb-8d0c-0976fbe828c4",
   "metadata": {},
   "source": [
    "# Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbbaea-73c8-4ea2-a864-347e67051ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bin_classification(x):\n",
    "#     return 1 if x >= 0.5 else 0\n",
    "# bin_class_vectorised = np.vectorize(bin_classification)\n",
    "\n",
    "\n",
    "# def regression_predict(w, x):\n",
    "#     return w * x\n",
    "# regression_predict_vectorized = np.vectorize(regression_predict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f295c-9d28-498d-9070-f705311b1428",
   "metadata": {},
   "source": [
    "# To do\n",
    "- how to do back prop for > 1 hidden layer\n",
    "- add bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f89418ac-0009-4081-9700-b48101b793de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Data_Helper():\n",
    "    def is_list_of_lists(container):        \n",
    "        if not isinstance(container, list):            \n",
    "            raise TypeError('Container must be of data type: List.')\n",
    "            return False\n",
    "        else:\n",
    "            for idx, item in enumerate(container):\n",
    "                if not isinstance(item, list):\n",
    "                    msg = 'Items in container must be of data type \"list\"'\n",
    "                    msg += f'Error item: index: {idx}.' \n",
    "                    raise TypeError(msg)                    \n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "class Sigmoid():\n",
    "    activation_type = 'Sigmoid'\n",
    "    \n",
    "    def execute(self, input_matrix):\n",
    "        z = np.exp(-input_matrix)\n",
    "        sig = 1 / (1 + z)      \n",
    "        return sig\n",
    "\n",
    "class Sigmoid_Stable():\n",
    "    activation_type = 'Sigmoid_Stable'\n",
    "    \n",
    "    def execute(self, input_matrix):\n",
    "        sig = np.where(input_matrix < 0, np.exp(input_matrix)/(1 + np.exp(input_matrix)), \n",
    "                       1/(1 + np.exp(-input_matrix)))\n",
    "        return sig\n",
    "    \n",
    "\n",
    "class Linear():\n",
    "    activation_type = 'Linear'\n",
    "    \n",
    "    def execute(self, input_matrix):        \n",
    "        return input_matrix * 1    \n",
    "    \n",
    "\n",
    "class Model():\n",
    "    \"\"\"\n",
    "        Model Error depends on ALL layers, not just the output layer,\n",
    "        hence, errors should be calc at this level, not at the output layer level.\n",
    "        \n",
    "        contains history of each epoc's weights, preds and cost\n",
    "        hence, for each epoc:\n",
    "            `layer class` takes forwards and predicts            \n",
    "            preds are stored in this `class Model`\n",
    "            costs is caculated and stored here\n",
    "            weights are stored here too.\n",
    "            \n",
    "        and \n",
    "        def .save_model_architecture(), saves to a pickle:\n",
    "            . the model (i.e. all layers and their parameters)\n",
    "        def .save_trained_model()\n",
    "            . saves the weights and bias\n",
    "        def .load_model_architecture()\n",
    "        def .load_trained_model()\n",
    "            load weights and bias and inits it to the right layer\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        self._layers = layers  # a list of layer objects        \n",
    "        self._preds = None\n",
    "        self._probs = None\n",
    "        self._errors = None\n",
    "        self._len_targets = None\n",
    "        self._cost = None\n",
    "        self._error_derivative = None\n",
    "        self._weight_delta = None\n",
    "        \n",
    "        \n",
    "    def print_model_architecture(self):\n",
    "        for idx, layer in enumerate(self._layers):\n",
    "            print(f\"\\nLayer #{idx}:\")\n",
    "            layer.print_layer_details()\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def matrix_mul_dims_ok(layer_prev, weights):\n",
    "        # class method\n",
    "        m, n1 = layer_prev.shape\n",
    "        print(f'\\n\\nLprev.shape: \\tm = {m} \\tby n = {n1}')\n",
    "\n",
    "        n2, p = weights.shape\n",
    "        print(f'x.shape: \\tn = {n2} \\tby p = {p}')\n",
    "\n",
    "        if n1 != n2:\n",
    "            print('n1 != n2, matrix multiplication will fail.\\n')\n",
    "            print('either A or B should be reshaped if possible.')\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    def train(self, X, y, epochs=1, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        X: train data\n",
    "        y: targets\n",
    "        epochs: Number of times we loop through a complete dataset\n",
    "                consisting of N rows.\n",
    "                \n",
    "        each epoch, we save a history of:\n",
    "        . weights, bias, preds, costs\n",
    "        \n",
    "        for each epoch:\n",
    "            forward once\n",
    "            get preds\n",
    "            calc error\n",
    "            calc cost\n",
    "            back prop (update weights)                \n",
    "        \n",
    "        \"\"\"\n",
    "        for epoch in self._epochs:\n",
    "            print(f\"epoch #: {epoch}\")\n",
    "            for idx, layer in enumerate(self._layers):\n",
    "                if layer_details['layer_type'].lower() == 'input layer':\n",
    "                    continue\n",
    "                else:\n",
    "                    layer.forward(self._layers[idx-1].get_layer_matrix())\n",
    "\n",
    "                if layer_details['name'].lower() == 'output':                   \n",
    "                    if layer_details['layer_type'].lower() == 'output_regression':\n",
    "                        self._preds = layer.predict()\n",
    "                    else:\n",
    "                        self._preds = layer.predict(threshold=threshold) \n",
    "                    \n",
    "                self._probs = layer.get_layer_matrix()\n",
    "                    \n",
    "\n",
    "    def predict(self, threshold=0.5):\n",
    "        # Forward Pass ONCE and does a prediction\n",
    "        pred = None\n",
    "        for idx, layer in enumerate(self._layers):\n",
    "            layer_details = layer.get_layer_details()\n",
    "            print(f\"\\nLayer #{idx}:\")\n",
    "            # print('*'*50)\n",
    "            # print(f\"name: \\t\\t{layer_details['name']}\")\n",
    "            # print(f\"layer_type: \\t{layer_details['layer_type']}\")\n",
    "            # print(f\"num_nodes_prev: {layer_details['num_nodes_prev']}\")\n",
    "            # print(f\"num_nodes: \\t{layer_details['num_nodes']}\")\n",
    "            # print(f\"layer_shape: \\t{layer_details['layer_shape']}\")\n",
    "                        \n",
    "            if layer_details['layer_type'].lower() == 'input layer':\n",
    "                continue\n",
    "            else:\n",
    "                # Forward Once\n",
    "                layer.forward(self._layers[idx-1].get_layer_matrix())    \n",
    "                \n",
    "                print(f\"after forward pass:\\n{layer.get_layer_matrix()}\")\n",
    "                \n",
    "            if layer_details['name'].lower() == 'output':                   \n",
    "                if layer_details['layer_type'].lower() == 'output_regression':\n",
    "                    self._preds = layer.predict()\n",
    "                else:\n",
    "                    self._preds = layer.predict(threshold=threshold) \n",
    "                    \n",
    "                self._probs = layer.get_layer_matrix()\n",
    "                return self._preds\n",
    "            \n",
    "    def get_proba(self):\n",
    "        return self._probs\n",
    "    \n",
    "    def get_model_error(self, targets):\n",
    "        # model's difference between predictions and targets\n",
    "        \n",
    "        if Data_Helper.is_list_of_lists(targets):\n",
    "            print('list of lists targets ok')\n",
    "            self._len_targets = len(targets)\n",
    "            # errors = preds - targets\n",
    "            # preds = weights * input\n",
    "            # so, errors = (weights * input) - targets \n",
    "            # targets and inputs are given, we can only adjust the weights to reduce the error\n",
    "            self._errors = self._preds - targets   # a matrix\n",
    "            return self._errors\n",
    "    \n",
    "    def get_model_cost(self, cost_fn='Mean Squared Error'):        \n",
    "        # sum(errors) / len(targets) to obtain a single scalar\n",
    "        # there are many types of cost fns e.g. \n",
    "        # For regression: \"Mean Absolute Error\", \"Mean Squared Error\"\n",
    "        # For classification: \"Binary Cross Entrophy\", \"Categorical Cross Entrophy\"\n",
    "        if cost_fn == 'Mean Squared Error':\n",
    "            self.cost = np.sum(np.square(self._errors)) / self._len_targets\n",
    "        elif cost_fn == 'Mean Absolute Error':\n",
    "            self.cost = np.sum(np.abs(self._errors)) / self._len_targets\n",
    "        return self.cost\n",
    "    \n",
    "    def get_weight_delta(self):\n",
    "        self._error_derivative = 2 * self._errors\n",
    "        \n",
    "        # self._weight_delta = self._error_derivative * Inputs        \n",
    "        # rc: inputs is the input layer or the preceding layer ?\n",
    "        \n",
    "        return self._weight_delta\n",
    "    \n",
    "    def update_weights(self):\n",
    "        # weights -= learning_rate * np.sum(self._weight_delta) / len(self._weight_delta)\n",
    "        pass\n",
    "                \n",
    "    def save_model_architecture(self):\n",
    "        pass\n",
    "    \n",
    "    def save_trained_model(self):\n",
    "        pass\n",
    "\n",
    "    def load_model_architecture(self):\n",
    "        pass\n",
    "    \n",
    "    def load_trained_model(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "        \n",
    "class Layer():\n",
    "    layer_type = 'Base Layer'\n",
    "    \n",
    "    def __init__(self, layer_name, nodes_prev_layer, nodes_in_layer):\n",
    "        self._layer_name = layer_name\n",
    "        self._nodes_prev_layer = nodes_prev_layer\n",
    "        self._nodes = nodes_in_layer\n",
    "    \n",
    "    def get_layer_details(self):\n",
    "        layer_details = {}\n",
    "        layer_details['name'] = self._layer_name\n",
    "        layer_details['layer_type'] = self.layer_type  # uses child class's class variable\n",
    "        layer_details['num_nodes_prev'] = self._nodes_prev_layer\n",
    "        layer_details['num_nodes'] = self._nodes\n",
    "        layer_details['layer_shape'] = self._layer_matrix.shape\n",
    "        layer_details['layer_matrix'] = self._layer_matrix\n",
    "        return layer_details\n",
    "    \n",
    "    def print_layer_details(self):\n",
    "        layer_details = self.get_layer_details()        \n",
    "        print('*'*50)\n",
    "        print(f\"name: \\t\\t{layer_details['name']}\")\n",
    "        print(f\"layer_type: \\t{layer_details['layer_type']}\")\n",
    "        print(f\"num_nodes_prev: {layer_details['num_nodes_prev']}\")\n",
    "        print(f\"num_nodes: \\t{layer_details['num_nodes']}\")\n",
    "        print(f\"layer_shape: \\t{layer_details['layer_shape']}\")\n",
    "        \n",
    "    \n",
    "    # def forward(self, X=None):\n",
    "    #     # stub fn, implementation is to be overriden in derived classes if required.\n",
    "    #     pass\n",
    "    \n",
    "    def get_layer_matrix(self):\n",
    "        return self._layer_matrix\n",
    "\n",
    "    \n",
    "class Input_Layer(Layer):\n",
    "    layer_type = 'Input Layer'\n",
    "    \n",
    "    def __init__(self, layer_name, nodes_prev_layer, nodes_in_layer, data):\n",
    "        super().__init__(layer_name, nodes_prev_layer, nodes_in_layer)  \n",
    "        \n",
    "        if Data_Helper.is_list_of_lists(data):\n",
    "            self._data = data\n",
    "            \n",
    "        self._layer_matrix = np.array(data).reshape(-1, self._nodes)  # representation of this layer\n",
    "\n",
    "    def data_wrangling_fns(self):\n",
    "        # placeholder - otherwise, no reason to have a child class just for input\n",
    "        pass\n",
    "    \n",
    "        \n",
    "class Fully_Connected_Layer(Layer):\n",
    "    layer_type = 'Fully Connected Layer'\n",
    "    \n",
    "    def __init__(self, layer_name, nodes_prev_layer, nodes_in_layer, act_fn):\n",
    "        super().__init__(layer_name, nodes_prev_layer, nodes_in_layer)  \n",
    "        \n",
    "        self._weights_matrix = np.ones(self._nodes_prev_layer * self._nodes)\n",
    "        # Todo: Uncomment next line when testing is over\n",
    "        #self._weights_matrix = np.random.rand(self._nodes_prev_layer * self._nodes)\n",
    "        self._weights_matrix = self._weights_matrix.reshape(self._nodes_prev_layer, self._nodes)\n",
    "               \n",
    "        self._layer_matrix = np.zeros(self._nodes).reshape(1,self._nodes)  # representation of this layer\n",
    "        \n",
    "        self.act_fn = act_fn\n",
    "\n",
    "    def get_layer_details(self):\n",
    "        layer_details = super().get_layer_details()\n",
    "        layer_details['weights_shape'] = self._weights_matrix.shape\n",
    "        layer_details['weights_matrix'] = self._weights_matrix\n",
    "        layer_details['activation'] = self.act_fn.activation_type\n",
    "        return layer_details\n",
    "    \n",
    "    def print_layer_details(self):\n",
    "        super().print_layer_details()\n",
    "        layer_details = self.get_layer_details()\n",
    "        print(f\"weights_shape: \\t{layer_details['weights_shape']}\")\n",
    "        print(f\"activation: \\t{layer_details['activation']}\")\n",
    "\n",
    "    def get_weights_matrix(self):\n",
    "        return self._weights_matrix\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(1,-1)\n",
    "            \n",
    "        # .sum( axis=0) collapses the rows into 1 row\n",
    "        #self._layer_matrix = np.sum(np.dot(X, self._weights_matrix), axis=0)        \n",
    "        self._layer_matrix = np.dot(X, self._weights_matrix)\n",
    "        \n",
    "        # print(f'before act fn: {self.get_layer_matrix()}')        \n",
    "        self._layer_matrix = self.act_fn.execute(self._layer_matrix)                \n",
    "        \n",
    "        if self._layer_matrix.ndim ==1:\n",
    "            self._layer_matrix = self._layer_matrix.reshape(1,-1)            \n",
    "    \n",
    "    def test(self):\n",
    "        self.act_fn.execute(888)\n",
    "       \n",
    "        \n",
    "class Output_Binary_Classification(Fully_Connected_Layer):\n",
    "    layer_type = 'Output_Binary_Classification'\n",
    "    \n",
    "    def __init__(self, layer_name, nodes_prev_layer, nodes_in_layer, act_fn):\n",
    "        nodes_in_layer = 1 # hardcode coz binary classification\n",
    "        \n",
    "        super().__init__(layer_name, nodes_prev_layer, nodes_in_layer, act_fn)  \n",
    "        \n",
    "        self._predicted_class = None\n",
    "    \n",
    "    def get_probability_matrix(self):\n",
    "        return self._layer_matrix\n",
    "        \n",
    "    def predict(self, threshold=0.5):\n",
    "        # returns an array of array, hence [0][0] to get the int\n",
    "\n",
    "        # both the below are the same, but the .astype() ver is supposed to be twice as fast\n",
    "        # but ver B can only produce 0 and 1 while ver A is more flexible\n",
    "        #self._predicted_class = np.where(self._layer_matrix >= threshold, 1, 0)]  # ver A\n",
    "        self._predicted_class = (self._layer_matrix>threshold).astype(int)  # ver B\n",
    "        # nb: .round() is the slowest, in some cases 10 times slower\n",
    "        # ver A and B are faster than list comprehension coz they are vectorized.\n",
    "        return self._predicted_class\n",
    "\n",
    "# not implemented, act fn sh be softmax    \n",
    "# class Output_MultiClass_Classification(Fully_Connected_Layer): # predict 1 class out of multiple classes \n",
    "# class Output_MultiLabel_Classification(Fully_Connected_Layer): # predict p-values of 1 or more classes\n",
    "                                                                 #   an input can belong to >1 class\n",
    "\n",
    "class Output_Regression(Fully_Connected_Layer):\n",
    "    layer_type = 'Output_Regression'\n",
    "    \n",
    "    def __init__(self, layer_name, nodes_prev_layer, nodes_in_layer, act_fn):\n",
    "        nodes_in_layer = 1 # hardcode coz regression\n",
    "        \n",
    "        super().__init__(layer_name, nodes_prev_layer, nodes_in_layer, act_fn)  \n",
    "        \n",
    "    def predict(self):        \n",
    "        return self._layer_matrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c769dd17-133e-4313-963f-96e084e2b142",
   "metadata": {},
   "source": [
    "### Test the NN Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff79ccac-5f91-4fed-94a2-d3d1bdc57d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Test the NN code    \n",
    "# data = [\n",
    "#     [1,1,1],\n",
    "#     [2,2,2],\n",
    "#     [3,3,3],\n",
    "#     [4,4,4]]\n",
    "                 \n",
    "# output_type = \"Binary Classification\"\n",
    "# #output_type = 'Regression'\n",
    "\n",
    "# if output_type == \"Binary Classification\":\n",
    "#     layers = [\n",
    "#         Input_Layer('Input', 0, 3, data),\n",
    "#         Fully_Connected_Layer('H1', 3, 5, Sigmoid()),\n",
    "#         Fully_Connected_Layer('H2', 5, 8, Sigmoid()),\n",
    "#         Output_Binary_Classification('Output', 8, 1, Sigmoid())    \n",
    "#     ]\n",
    "# elif output_type == 'Regression':    \n",
    "#     layers = [\n",
    "#         Input_Layer('Input', 0, 3, data),\n",
    "#         Fully_Connected_Layer('H1', 3, 5, Sigmoid()),\n",
    "#         Fully_Connected_Layer('H2', 5, 8, Sigmoid()),\n",
    "#         Output_Regression('Output', 8, 1, Linear())\n",
    "#     ]\n",
    "\n",
    "# model = Model(layers)\n",
    "# #model.print_model_architecture()\n",
    "\n",
    "# if output_type == 'Regression':\n",
    "#     pred = model.predict()\n",
    "#     print(f\"\\nModel predicts: {pred:0.2f}\")\n",
    "# else:\n",
    "#     pred = model.predict(threshold=0.5)\n",
    "#     print(f\"\\nModel predicts: 'Class {pred}`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505ef14-d42a-4b81-859d-c1618dc989aa",
   "metadata": {},
   "source": [
    "# Temp Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4f631-f2a6-410b-b899-2d3585e17921",
   "metadata": {},
   "source": [
    "##### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "550ddeec-36a6-419b-be67-b200b3e7d3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer #0:\n",
      "\n",
      "Layer #1:\n",
      "after forward pass:\n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]]\n",
      "\n",
      "Layer #2:\n",
      "after forward pass:\n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]]\n",
      "\n",
      "Model proba: \n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]]\n",
      "\n",
      "Regression:\n",
      "targets:\n",
      "[[2], [4], [6], [8]]\n",
      "Model predicts: \n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]]\n",
      "list of lists targets ok\n",
      "Model Errors: \n",
      "[[-1.]\n",
      " [-2.]\n",
      " [-3.]\n",
      " [-4.]]\n",
      "Model Cost: \n",
      "7.5\n"
     ]
    }
   ],
   "source": [
    "data = [[1],[2],[3],[4]]\n",
    "targets = [[2],[4],[6],[8]]\n",
    "#targets = [[1],[2],[3],[4]]\n",
    "                 \n",
    "layers = [\n",
    "        Input_Layer('Input', 0, 1, data),\n",
    "        Fully_Connected_Layer('H1', 1, 1, Linear()),\n",
    "        Output_Regression('Output', 1, 1, Linear())\n",
    "]\n",
    "\n",
    "model = Model(layers)\n",
    "#model.train()\n",
    "\n",
    "#model.print_model_architecture()\n",
    "pred = model.predict()\n",
    "probs = model.get_proba()\n",
    "print(f\"\\nModel proba: \\n{probs}\")\n",
    "print(\"\\nRegression:\")\n",
    "print(f'targets:\\n{targets}')\n",
    "print(f\"Model predicts: \\n{pred}\")\n",
    "errors = model.get_model_error(targets)\n",
    "print(f\"Model Errors: \\n{errors}\")\n",
    "cost = model.get_model_cost(cost_fn='Mean Squared Error')\n",
    "print(f\"Model Cost: \\n{cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fecc31-7e39-4d2a-9a69-74b625bd2ec0",
   "metadata": {},
   "source": [
    "##### Bin Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56cbce5d-71f6-4421-91c1-532fc6f11ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer #0:\n",
      "\n",
      "Layer #1:\n",
      "after forward pass:\n",
      "[[1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]]\n",
      "\n",
      "Layer #2:\n",
      "after forward pass:\n",
      "[[0.73105858]\n",
      " [0.88079708]\n",
      " [0.95257413]\n",
      " [0.98201379]]\n",
      "\n",
      "Model proba: \n",
      "[[0.73105858]\n",
      " [0.88079708]\n",
      " [0.95257413]\n",
      " [0.98201379]]\n",
      "\n",
      "Bin Classification\n",
      "targets:\n",
      "[[1], [0], [0], [1]]\n",
      "Model predicts: \n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "list of lists targets ok\n",
      "Model errors: \n",
      "[[-1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " [ 0]]\n",
      "Model Cost: \n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "data = [[1],[2],[3],[4]]\n",
    "targets = [[1],[0],[0],[1]]\n",
    "                 \n",
    "layers = [\n",
    "        Input_Layer('Input', 0, 1, data),\n",
    "        Fully_Connected_Layer('H1', 1, 1, Linear()),\n",
    "        Output_Binary_Classification('Output', 1, 1, Sigmoid())\n",
    "]\n",
    "\n",
    "model = Model(layers)\n",
    "#model.print_model_architecture()\n",
    "pred = model.predict(threshold=0.75)\n",
    "probs = model.get_proba()\n",
    "print(f\"\\nModel proba: \\n{probs}\")\n",
    "print(\"\\nBin Classification\")\n",
    "print(f'targets:\\n{targets}')\n",
    "print(f\"Model predicts: \\n{pred}\")\n",
    "errors = model.get_model_error(targets)\n",
    "print(f\"Model errors: \\n{errors}\")\n",
    "cost = model.get_model_cost()\n",
    "print(f\"Model Cost: \\n{cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4fa11-c4d5-4b4a-8e05-aded1f9e2f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
